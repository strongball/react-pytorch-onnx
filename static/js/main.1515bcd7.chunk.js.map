{"version":3,"sources":["utils/image.ts","utils/fns.ts","containers/Home.tsx","App.tsx","index.tsx"],"names":["fromHWCToCHW","data","options","width","height","dataFromImage","ndarray","Float32Array","dataProcessed","ops","divseq","assign","pick","topk","k","Array","from","map","value","index","sort","a","b","slice","imageOptions","loadModel","path","session","InferenceSession","HomeContainer","props","videoRef","useRef","canvasRef","useState","loading","setLoading","topkResult","setTopkResult","sessionPromise","process","modelInputChange","files","length","current","predit","alert","console","log","canvas","arrImage","getContext","getImageData","imageCHW","inputTensor","Tensor","run","outputMap","output","values","next","topk5","error","startTracking","navigator","mediaDevices","getUserMedia","audio","video","facingMode","aspectRatio","stream","srcObject","type","onChange","e","target","onClick","getTracks","forEach","track","stop","source","sourceSize","targetSize","hRatio","vRatio","ratio","Math","max","drawWidth","drwaHeight","centerShift_x","centerShift_y","drawImage","coverDrawToCanvas","videoWidth","videoHeight","ref","autoPlay","style","display","id","item","paddingRight","ImageNetClassname","toString","toFixed","App","className","Home","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"yo6BA+GO,SAASA,EAAaC,EAAWC,GAAmC,IAC/DC,EAAkBD,EAAlBC,MAAOC,EAAWF,EAAXE,OACTC,EAAgBC,IAAQ,IAAIC,aAAaN,GAAO,CAACE,EAAOC,EAAQ,IAChEI,EAAgBF,IAAQ,IAAIC,aAAaJ,EAAQC,EAAS,GAAI,CAAC,EAAG,EAAGA,EAAQD,IAMnF,OALAM,IAAIC,OAAOL,EAAe,KAC1BI,IAAIE,OAAOH,EAAcI,KAAK,EAAG,EAAG,KAAM,MAAOP,EAAcO,KAAK,KAAM,KAAM,IAChFH,IAAIE,OAAOH,EAAcI,KAAK,EAAG,EAAG,KAAM,MAAOP,EAAcO,KAAK,KAAM,KAAM,IAChFH,IAAIE,OAAOH,EAAcI,KAAK,EAAG,EAAG,KAAM,MAAOP,EAAcO,KAAK,KAAM,KAAM,IAExEJ,EAAcP,KCpHnB,SAASY,EAAKZ,GAA4B,IAARa,EAAO,uDAAH,EACzC,OAAOC,MAAMC,KAAKf,GACbgB,KAAgB,SAACC,EAAOC,GAAR,MAAmB,CAChCA,QACAD,YAEHE,MAAK,SAACC,EAAGC,GAAJ,OAAUA,EAAEJ,MAAQG,EAAEH,SAC3BK,MAAM,EAAGT,G,mBCJZU,EAA0B,CAC5BrB,MAAO,IACPC,OAAQ,K,SAEGqB,E,8EAAf,WAAyBC,GAAzB,eAAAL,EAAA,6DACUM,EAAU,IAAIC,mBAAiB,IADzC,SAEUD,EAAQF,UAAUC,GAF5B,gCAGWC,GAHX,4C,sBAMA,IA6GeE,EA7GwB,SAACC,GACpC,IAAMC,EAAWC,iBAAyB,MACpCC,EAAYD,iBAA0B,MAFE,EAGhBE,oBAAkB,GAHF,mBAGvCC,EAHuC,KAG9BC,EAH8B,OAKVF,mBAAuB,IALb,mBAKvCG,EALuC,KAK3BC,EAL2B,KAOxCC,EAAiBP,iBACnBP,EAAUe,gDAGRC,EAAgB,uCAAG,WAAOC,GAAP,SAAArB,EAAA,yDAChBqB,GAA0B,IAAjBA,EAAMC,OADC,iDAIrBJ,EAAeK,QAAUnB,EAAUiB,EAAM,IAJpB,2CAAH,sDAOhBG,EAAM,uCAAG,wCAAAxB,EAAA,yDACNY,EAAUW,QADJ,oDAINL,EAAeK,QAJT,uBAKPE,MAAM,yCALC,iCAQXV,GAAW,GARA,SAUPW,QAAQC,IAAI,cAVL,UAWeT,EAAeK,QAX9B,eAWDjB,EAXC,OFsEWsB,EE1DahB,EAAUW,QAAnCM,EF2DED,EAAOE,WAAW,MACRC,aAAa,EAAG,EAAGH,EAAO9C,MAAO8C,EAAO7C,QACjDH,KE5DHoD,EAAWrD,EAAakD,EAAU1B,GAClC8B,EAAc,IAAIC,SAAOF,EAAU,UAAW,CAAC,EAAG,EAAG,IAAK,MAdzD,UAeiB1B,EAAQ6B,IAAI,CAACF,IAf9B,QAeDG,EAfC,OAgBDC,EAAuBD,EAAUE,SAASC,OAAO1C,MAAMjB,KACvD4D,EAAQhD,EAAK6C,GACnBpB,EAAcuB,GAlBP,kDAoBPd,QAAQe,MAAR,MApBO,QAsBX1B,GAAW,GAtBA,kCFsEZ,IAAuBa,IEtEX,qBAAH,qDAwCNc,EAAa,uCAAG,4BAAA1C,EAAA,0DACdU,EAASa,UAAWoB,UAAUC,aAAaC,aAD7B,gCAEOF,UAAUC,aAAaC,aAAa,CACrDC,OAAO,EACPC,MAAO,CACHjE,MAAO,IACPC,OAAQ,IACRiE,WAAY,cACZC,YAAa,KARP,OAERC,EAFQ,OAWdxC,EAASa,QAAQ4B,UAAYD,EAC7BxB,QAAQC,IAAIjB,EAASa,SAZP,2CAAH,qDAuBnB,OACI,gCACI,gCACI,4DACA,uBAAO6B,KAAK,OAAOC,SAAU,SAACC,GAAD,aAAOlC,EAAgB,QAAE,EAAAkC,EAAEC,cAAJ,aAAE,EAAUlC,aAEpE,uBACA,wBAAQmC,QAASd,EAAjB,sCACA,wBAAQc,QAhBK,WAAO,IAAD,GACvB,UAAI9C,EAASa,eAAb,aAAI,EAAkB4B,aACSzC,EAASa,QAAQ4B,UACtCM,YAAYC,SAAQ,SAACC,GAAD,OAAWA,EAAMC,UAC3ClD,EAASa,QAAQ4B,UAAY,OAY7B,sCACA,wBAAQK,QA/CK,WACb9C,EAASa,SAAWX,EAAUW,WFgBnC,SACHsC,EACAjC,EACA/C,GACD,IACSiF,EAA2BjF,EAA3BiF,WAAYC,EAAelF,EAAfkF,WACdC,EAASD,EAAWjF,MAAQgF,EAAWhF,MACvCmF,EAASF,EAAWhF,OAAS+E,EAAW/E,OACxCmF,EAAQC,KAAKC,IAAIJ,EAAQC,GACzBI,EAAYP,EAAWhF,MAAQoF,EAC/BI,EAAaR,EAAW/E,OAASmF,EACjCK,GAAiBR,EAAWjF,MAAQuF,GAAa,EACjDG,GAAiBT,EAAWhF,OAASuF,GAAc,EAEzC1C,EAAOE,WAAW,MAC1B2C,UACJZ,EACA,EACA,EACAC,EAAWhF,MACXgF,EAAW/E,OACXwF,EACAC,EACAH,EACAC,GEvCII,CAAkBhE,EAASa,QAASX,EAAUW,QAAS,CACnDuC,WAAY,CACRhF,MAAO4B,EAASa,QAAQoD,WACxB5F,OAAQ2B,EAASa,QAAQqD,aAE7Bb,WAAY,CACRjF,MAAO8B,EAAUW,QAAQzC,MACzBC,OAAQ6B,EAAUW,QAAQxC,UAGlCyC,MAmCA,0BAEA,8BACI,uBAAOqD,IAAKnE,EAAUoE,UAAQ,EAAChG,MAAM,MAAMC,OAAO,UAErD+B,GAAW,6CACZ,wBAAQiE,MAAO,CAAEC,QAAS,QAAUH,IAAKjE,EAAWqE,GAAG,SAASnG,MAAM,MAAMC,OAAO,QACnF,8BACKiC,EAAWpB,KAAI,SAACsF,EAAMpF,GAAP,OACZ,gCACI,uBAAMiF,MAAO,CAAEI,aAAc,GAA7B,UAAmCrF,EAAQ,EAA3C,OACA,+BAAOsF,EAAkBF,EAAKpF,MAAMuF,cACpC,sCAAsB,IAAbH,EAAKrF,OAAayF,QAAQ,GAAnC,UAHMJ,EAAKpF,gBC5DpByF,EA5CO,WAelB,OACI,qBAAKC,UAAU,MAAf,SACI,cAACC,EAAD,OCxBZC,IAASC,OACL,cAAC,IAAMC,WAAP,UACI,cAAC,EAAD,MAEJC,SAASC,eAAe,W","file":"static/js/main.1515bcd7.chunk.js","sourcesContent":["import ndarray from 'ndarray';\nimport ops from 'ndarray-ops';\n\nexport function loadImage(url: string): Promise<HTMLImageElement> {\n    return new Promise((resolve, reject) => {\n        const im = new Image();\n        im.crossOrigin = 'anonymous';\n        im.src = url;\n        im.onload = () => {\n            resolve(im);\n        };\n    });\n}\n\nexport interface ImageSize {\n    width: number;\n    height: number;\n}\ninterface DrawImageToCanvasOptions {\n    canvas?: HTMLCanvasElement;\n    imageSize: ImageSize;\n}\nexport async function drawImageToCanvas(\n    imageUrl: string,\n    options: DrawImageToCanvasOptions\n): Promise<HTMLCanvasElement> {\n    const canvas = options.canvas || document.createElement('canvas');\n    const image = await loadImage(imageUrl);\n    resizeDrawToCanvas(image, canvas, {\n        sourceSize: {\n            width: image.width,\n            height: image.height,\n        },\n        targetSize: {\n            width: options.imageSize.width,\n            height: options.imageSize.height,\n        },\n    });\n    return canvas;\n}\n\ninterface ResizeDrawToCanvasOptions {\n    sourceSize: ImageSize;\n    targetSize: ImageSize;\n}\nexport function resizeDrawToCanvas(\n    source: CanvasImageSource,\n    canvas: HTMLCanvasElement,\n    options: ResizeDrawToCanvasOptions\n) {\n    const { sourceSize, targetSize } = options;\n    const hRatio = targetSize.width / sourceSize.width;\n    const vRatio = targetSize.height / sourceSize.height;\n    const ratio = Math.min(hRatio, vRatio);\n    const drawWidth = sourceSize.width * ratio;\n    const drwaHeight = sourceSize.height * ratio;\n    const centerShift_x = (targetSize.width - drawWidth) / 2;\n    const centerShift_y = (targetSize.height - drwaHeight) / 2;\n\n    const context = canvas.getContext('2d')!;\n    context.drawImage(\n        source,\n        0,\n        0,\n        sourceSize.width,\n        sourceSize.height,\n        centerShift_x,\n        centerShift_y,\n        drawWidth,\n        drwaHeight\n    );\n}\n\ninterface CoverDrawToCanvasOptions {\n    sourceSize: ImageSize;\n    targetSize: ImageSize;\n}\nexport function coverDrawToCanvas(\n    source: CanvasImageSource,\n    canvas: HTMLCanvasElement,\n    options: CoverDrawToCanvasOptions\n) {\n    const { sourceSize, targetSize } = options;\n    const hRatio = targetSize.width / sourceSize.width;\n    const vRatio = targetSize.height / sourceSize.height;\n    const ratio = Math.max(hRatio, vRatio);\n    const drawWidth = sourceSize.width * ratio;\n    const drwaHeight = sourceSize.height * ratio;\n    const centerShift_x = (targetSize.width - drawWidth) / 2;\n    const centerShift_y = (targetSize.height - drwaHeight) / 2;\n\n    const context = canvas.getContext('2d')!;\n    context.drawImage(\n        source,\n        0,\n        0,\n        sourceSize.width,\n        sourceSize.height,\n        centerShift_x,\n        centerShift_y,\n        drawWidth,\n        drwaHeight\n    );\n}\n\nexport function canvasToArray(canvas: HTMLCanvasElement): Uint8ClampedArray {\n    const context = canvas.getContext('2d')!;\n    const imageData = context.getImageData(0, 0, canvas.width, canvas.height);\n    return imageData.data;\n}\n\nexport function fromHWCToCHW(data: any, options: ImageSize): Float32Array {\n    const { width, height } = options;\n    const dataFromImage = ndarray(new Float32Array(data), [width, height, 4]);\n    const dataProcessed = ndarray(new Float32Array(width * height * 3), [1, 3, height, width]);\n    ops.divseq(dataFromImage, 255.0);\n    ops.assign(dataProcessed.pick(0, 0, null, null), dataFromImage.pick(null, null, 0));\n    ops.assign(dataProcessed.pick(0, 1, null, null), dataFromImage.pick(null, null, 1));\n    ops.assign(dataProcessed.pick(0, 2, null, null), dataFromImage.pick(null, null, 2));\n\n    return (dataProcessed.data as any) as Float32Array;\n}\n","export interface TopkResult {\n    index: number;\n    value: number;\n}\nexport function topk(data: Float32Array, k = 5) {\n    return Array.from(data)\n        .map<TopkResult>((value, index) => ({\n            index,\n            value,\n        }))\n        .sort((a, b) => b.value - a.value)\n        .slice(0, k);\n}\n","import React, { useEffect, useState, useRef } from 'react';\nimport { Tensor, InferenceSession } from 'onnxjs';\nimport { canvasToArray, drawImageToCanvas, fromHWCToCHW, ImageSize, coverDrawToCanvas } from '../utils/image';\nimport { topk, TopkResult } from '../utils/fns';\n\nimport ImageNetClassname from '../classname.json';\n\nconst imageOptions: ImageSize = {\n    width: 224,\n    height: 224,\n};\nasync function loadModel(path: Blob | string) {\n    const session = new InferenceSession({});\n    await session.loadModel(path as string);\n    return session;\n}\ninterface Props {}\nconst HomeContainer: React.FC<Props> = (props) => {\n    const videoRef = useRef<HTMLVideoElement>(null);\n    const canvasRef = useRef<HTMLCanvasElement>(null);\n    const [loading, setLoading] = useState<boolean>(false);\n\n    const [topkResult, setTopkResult] = useState<TopkResult[]>([]);\n\n    const sessionPromise = useRef<Promise<InferenceSession>>(\n        loadModel(process.env.PUBLIC_URL + '/mobilenet_v3_small.onnx')\n    );\n\n    const modelInputChange = async (files?: File[]) => {\n        if (!files || files.length === 0) {\n            return;\n        }\n        sessionPromise.current = loadModel(files[0]);\n    };\n\n    const predit = async () => {\n        if (!canvasRef.current) {\n            return;\n        }\n        if (!sessionPromise.current) {\n            alert('沒有選擇模型!');\n            return;\n        }\n        setLoading(true);\n        try {\n            console.log('start pred');\n            const session = await sessionPromise.current;\n            const arrImage = canvasToArray(canvasRef.current);\n            const imageCHW = fromHWCToCHW(arrImage, imageOptions);\n            const inputTensor = new Tensor(imageCHW, 'float32', [1, 3, 224, 224]);\n            const outputMap = await session.run([inputTensor]);\n            const output: Float32Array = outputMap.values().next().value.data;\n            const topk5 = topk(output);\n            setTopkResult(topk5);\n        } catch (err) {\n            console.error(err);\n        }\n        setLoading(false);\n    };\n\n    const captureVideo = () => {\n        if (videoRef.current && canvasRef.current) {\n            coverDrawToCanvas(videoRef.current, canvasRef.current, {\n                sourceSize: {\n                    width: videoRef.current.videoWidth,\n                    height: videoRef.current.videoHeight,\n                },\n                targetSize: {\n                    width: canvasRef.current.width,\n                    height: canvasRef.current.height,\n                },\n            });\n            predit();\n        }\n    };\n    const startTracking = async () => {\n        if (videoRef.current && navigator.mediaDevices.getUserMedia) {\n            const stream = await navigator.mediaDevices.getUserMedia({\n                audio: false,\n                video: {\n                    width: 480,\n                    height: 360,\n                    facingMode: 'environment',\n                    aspectRatio: 1,\n                },\n            });\n            videoRef.current.srcObject = stream;\n            console.log(videoRef.current);\n        }\n    };\n    const stopTracking = () => {\n        if (videoRef.current?.srcObject) {\n            const steam: MediaStream = videoRef.current.srcObject as MediaStream;\n            steam.getTracks().forEach((track) => track.stop());\n            videoRef.current.srcObject = null;\n        }\n    };\n\n    return (\n        <div>\n            <div>\n                <span>更換模型</span>\n                <input type=\"file\" onChange={(e) => modelInputChange((e.target?.files as any) as File[])}></input>\n            </div>\n            <hr />\n            <button onClick={startTracking}>開始錄影</button>\n            <button onClick={stopTracking}>停止錄影</button>\n            <button onClick={captureVideo}>擷取</button>\n\n            <div>\n                <video ref={videoRef} autoPlay width=\"224\" height=\"224\"></video>\n            </div>\n            {loading && <div>Loading...</div>}\n            <canvas style={{ display: 'none' }} ref={canvasRef} id=\"canvas\" width=\"224\" height=\"224\" />\n            <div>\n                {topkResult.map((item, index) => (\n                    <div key={item.index}>\n                        <span style={{ paddingRight: 8 }}>{index + 1}.</span>\n                        <span>{ImageNetClassname[item.index.toString() as '0']}</span>\n                        <span>({(item.value * 100).toFixed(2)}%)</span>\n                    </div>\n                ))}\n            </div>\n        </div>\n    );\n};\nexport default HomeContainer;\n","import React, { useEffect } from 'react';\nimport logo from './logo.svg';\nimport HomeContainer from './containers/Home';\nimport { Tensor, InferenceSession } from 'onnxjs';\nimport ndarray from 'ndarray';\nimport ops from 'ndarray-ops';\n\n// const image = new Image();\n// image.src = './dog.jpg';\n// image.onload = () => {\n//     console.log('onload');\n// };\nconst App: React.FC = () => {\n    // const session = new InferenceSession();\n    // useEffect(() => {\n    //     (async () => {\n    //         await session.loadModel('./model.onnx');\n    //         const data = getImageData();\n    //         const pData = preprocess(data).data;\n    //         const inputTensor = new onnx.Tensor(pData as any, 'float32', [1, 3, 224, 224]);\n    //         const outputMap = await session.run([inputTensor]);\n    //         const outputData = outputMap.values().next().value.data;\n    //         console.log(outputData.indexOf(Math.max(...outputData)));\n    //         console.log(outputData);\n    //     })();\n    //     // loadMobileNet();\n    // }, []);\n    return (\n        <div className=\"App\">\n            <HomeContainer></HomeContainer>\n        </div>\n    );\n};\n\n// function getImageData(modelWidth = 224, modelHeight = 224) {\n//     const canvas = document.createElement('canvas');\n//     canvas.width = modelWidth;\n//     canvas.height = modelHeight;\n//     const context = canvas.getContext('2d')!;\n//     context.drawImage(image, 0, 0);\n\n//     const imageData = context.getImageData(0, 0, canvas.width, canvas.height);\n//     return imageData.data;\n// }\n\n// function preprocess(data: any, width = 224, height = 224) {\n//     const dataFromImage = ndarray(new Float32Array(data), [width, height, 4]);\n//     const dataProcessed = ndarray(new Float32Array(width * height * 3), [1, 3, height, width]);\n\n//     ops.divseq(dataFromImage, 255.0);\n//     ops.assign(dataProcessed.pick(0, 0, null, null), dataFromImage.pick(null, null, 0));\n//     ops.assign(dataProcessed.pick(0, 1, null, null), dataFromImage.pick(null, null, 1));\n//     ops.assign(dataProcessed.pick(0, 2, null, null), dataFromImage.pick(null, null, 2));\n\n//     return dataProcessed;\n// }\nexport default App;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport App from './App';\n// import reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n    <React.StrictMode>\n        <App />\n    </React.StrictMode>,\n    document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\n// reportWebVitals();\n"],"sourceRoot":""}